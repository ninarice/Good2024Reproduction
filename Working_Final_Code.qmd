---
title: "Working_Final_Code"
format: html
editor: visual
---

# Working_Final_Code

##### Loading data and libraries

```{r, message=FALSE}

# Load libraries
library(mice)
library(naniar)
library(tidyverse)
library(broom) 
library(stargazer)
library(caret)
library(ggplot2)
library(logistf)
library(sandwich)
library(lmtest)
library(pROC)
library(knitr)
library(texreg)
library(lubridate)
library(maps)
library(rworldmap)

# Load data
repdata <- read.csv("PADD_Agreement Level.csv")

```

##### Data Preparation and Cleaning (General)

```{r}

# Count missing values for the dependent and independent variables
missing_counts <- repdata %>%
  summarise(
    Missing_GeWom = sum(is.na(GeWom)),
    Missing_FemSig_P = sum(is.na(FemSig_P)),
    Missing_FemNeg_P = sum(is.na(FemNeg_P)),
    Missing_FemMed_P = sum(is.na(FemMed_P)),
    Missing_FemOb_P = sum(is.na(FemOb_P)),
    Total_Missing_Rows = sum(!complete.cases(select(., GeWom, FemSig_P, FemNeg_P, FemMed_P, FemOb_P)))
  )

# Print results
missing_counts

# Visualize missingness
vis_miss(repdata) + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1, size = 3))

```

## Original Paper

##### Data Preparation

```{r}

# Create and trim datasets for each model (removing rows with missing IVs and selecting only relevant columns)
repdata_sig <- repdata %>% drop_na(GeWom, FemSig_P) %>% select(GeWom, FemSig_P)
repdata_neg <- repdata %>% drop_na(GeWom, FemNeg_P) %>% select(GeWom, FemNeg_P)
repdata_med <- repdata %>% drop_na(GeWom, FemMed_P) %>% select(GeWom, FemMed_P)
repdata_ob  <- repdata %>% drop_na(GeWom, FemOb_P)  %>% select(GeWom, FemOb_P)

sapply(list(repdata_sig, repdata_neg, repdata_med, repdata_ob), function(df) sum(is.na(df)))

```

### OLS Regression Models as seen in Table 4:

```{r, warning=FALSE}

# Convert GeWom to numeric for OLS models
repdata_sig$GeWom <- as.numeric(as.character(repdata_sig$GeWom))
repdata_neg$GeWom <- as.numeric(as.character(repdata_neg$GeWom))
repdata_med$GeWom <- as.numeric(as.character(repdata_med$GeWom))
repdata_ob$GeWom <- as.numeric(as.character(repdata_ob$GeWom))

# Define models
ols1 <- lm(GeWom ~ FemSig_P, data = repdata_sig)  # Women Signatories
ols2 <- lm(GeWom ~ FemNeg_P, data = repdata_neg)  # Women Negotiators
ols3 <- lm(GeWom ~ FemMed_P, data = repdata_med)  # Women Mediators
ols4 <- lm(GeWom ~ FemOb_P, data = repdata_ob)   # Women Observers

# Generate regression table
stargazer(ols1, ols2, ols3, ols4,
          title = "Percentage Measurement of Women Delegates (OLS Regression)",
          dep.var.labels = "Provisions for Women (GeWom)",
          covariate.labels = c("Women Signatories", "Women Negotiators", "Women Mediators", "Women Observers"),
          omit.stat = c("aic", "bic"),
          add.lines = list(
            c("Residual Std. Error", round(c(summary(ols1)$sigma, summary(ols2)$sigma, summary(ols3)$sigma, summary(ols4)$sigma), 3)),
            c("F-statistic", round(c(summary(ols1)$fstatistic[1], summary(ols2)$fstatistic[1], summary(ols3)$fstatistic[1], summary(ols4)$fstatistic[1]), 3))
          ),
          star.cutoffs = c(0.1, 0.05, 0.01),
          intercept.bottom = TRUE,
          type = "text")

```

##### Standard Errors:

```{r}

summary(ols1)
coeftest(ols1, vcov = vcovHC(ols1, type = "HC0"))  # Basic robust SE
coeftest(ols1, vcov = vcovHC(ols1, type = "HC1"))  # Slightly adjusted
coeftest(ols1, vcov = vcovHC(ols1, type = "HC4"))  # More aggressive

```

#### Correction of Standard Errors

We saw very slight changes in standard errors

```{r}

# Apply robust standard errors
ols1_robust <- coeftest(ols1, vcov = vcovHC(ols1, type = "HC3"))
ols2_robust <- coeftest(ols2, vcov = vcovHC(ols2, type = "HC3"))
ols3_robust <- coeftest(ols3, vcov = vcovHC(ols3, type = "HC3"))
ols4_robust <- coeftest(ols4, vcov = vcovHC(ols4, type = "HC3"))

# Function to extract robust standard errors
robust_se <- function(model) {
  sqrt(diag(vcovHC(model, type = "HC3")))
}

summary(ols1)  # Compare with
coeftest(ols1, vcov = vcovHC(ols1, type = "HC0"))  # Basic robust SE
coeftest(ols1, vcov = vcovHC(ols1, type = "HC1"))  # Slightly adjusted
coeftest(ols1, vcov = vcovHC(ols1, type = "HC4"))  # More aggressive

```

### Cross Validation for OLS

```{r}

# Set up 10-fold cross-validation
ctrl <- trainControl(method = "cv", number = 10)

# Cross-validation for OLS models
cv_ols_sig <- train(GeWom ~ FemSig_P, data = repdata_sig, method = "lm", trControl = ctrl)

# Print results
print(cv_ols_sig)

```

## Replication

##### Data Preparation

```{r}

# Create and trim datasets for Firth regression (GeWom as factor)
repdata_sig_firth <- repdata %>% 
  drop_na(GeWom, FemSig_P) %>% 
  select(GeWom, FemSig_P) %>% 
  mutate(GeWom = factor(GeWom, levels = c(0, 1), labels = c("No", "Yes")))

repdata_neg_firth <- repdata %>% 
  drop_na(GeWom, FemNeg_P) %>% 
  select(GeWom, FemNeg_P) %>% 
  mutate(GeWom = factor(GeWom, levels = c(0, 1), labels = c("No", "Yes")))

repdata_med_firth <- repdata %>% 
  drop_na(GeWom, FemMed_P) %>% 
  select(GeWom, FemMed_P) %>% 
  mutate(GeWom = factor(GeWom, levels = c(0, 1), labels = c("No", "Yes")))

repdata_ob_firth <- repdata %>% 
  drop_na(GeWom, FemOb_P) %>% 
  select(GeWom, FemOb_P) %>% 
  mutate(GeWom = factor(GeWom, levels = c(0, 1), labels = c("No", "Yes")))

# Check that both levels exist in each dataset
print(table(repdata_sig_firth$GeWom))  
print(table(repdata_neg_firth$GeWom))  
print(table(repdata_med_firth$GeWom))  
print(table(repdata_ob_firth$GeWom))  

```

### Alternative Model: Firth Regression: GeWom \~ FemSig_P

```{r, message=FALSE}

# Define firth regression models
firth1 <- logistf(GeWom ~ FemSig_P, data = repdata_sig_firth)
firth2 <- logistf(GeWom ~ FemNeg_P, data = repdata_neg_firth)
firth3 <- logistf(GeWom ~ FemMed_P, data = repdata_med_firth)
firth4 <- logistf(GeWom ~ FemOb_P, data = repdata_ob_firth)

# Function to extract model results
convert_firth <- function(model) {
  coefs <- model$coefficients
  ses <- sqrt(diag(vcov(model)))
  pvals <- model$prob
  tr <- createTexreg(
    coef.names = names(coefs),
    coef = coefs,
    se = ses,
    pvalues = pvals
  )
  return(tr)
}

# Convert all models
firth1_tex <- convert_firth(firth1)
firth2_tex <- convert_firth(firth2)
firth3_tex <- convert_firth(firth3)
firth4_tex <- convert_firth(firth4)

# Generate table
screenreg(list(firth1_tex, firth2_tex, firth3_tex, firth4_tex),
          custom.model.names = c("(1)", "(2)", "(3)", "(4)"),
          custom.coef.names = c("Intercept", "Women Signatories", "Women Negotiators", "Women Mediators", "Women Observers"),
          custom.header = list("Provisions for Women (GeWom)" = 1:4),
          stars = c(0.1, 0.05, 0.01),
          digits = 3)

```

### Cross-Validation for FemSig_P

Opted for a manual cross validation method given constant stopping cues and error messages.

```{r}

# Set number of folds
k <- 10

# Create stratified folds
set.seed(123)
folds <- createFolds(repdata_sig_firth$GeWom, k = k, list = TRUE)

# Initialize vector (to store accuracy per fold)
cv_results <- c()

# Perform manual k-fold cross-validation
for (i in seq_along(folds)) {
  
  # Split into training and validation sets
  train_data <- repdata_sig_firth[-folds[[i]], ]
  test_data  <- repdata_sig_firth[folds[[i]], ]
  
  # Train Firth logistic regression
  model <- logistf(GeWom ~ FemSig_P, data = train_data)
  
  # Predict on validation set
  pred_probs <- predict(model, newdata = test_data, type = "response")
  
  # Convert probabilities to binary predictions (0.5 threshold)
  pred_class <- ifelse(pred_probs > 0.5, "Yes", "No")
  
  # Compute accuracy for this fold
  fold_accuracy <- mean(pred_class == test_data$GeWom, na.rm = TRUE)
  
  # Store accuracy
  cv_results <- c(cv_results, fold_accuracy)
}

# Print Cross-Validation Results
cat("Mean Accuracy Across Folds:", mean(cv_results), "\n")
cat("Standard Deviation of Accuracy:", sd(cv_results), "\n")

```

### Alternative Model 2: Firth Regression with Covariates `Dat` and `Con`

#### Data Preparation

```{r}
# Convert `Dat` to Date format and extract year
repdata$Dat <- as.Date(repdata$Dat, format = "%Y-%m-%d")
repdata$Year <- year(repdata$Dat)

# Create 10-year bins for `Year`
repdata <- repdata %>%
  mutate(YearGroup = cut(Year, 
                         breaks = seq(1990, 2030, by = 10), # Only from 1990 onwards
                         include.lowest = TRUE, 
                         labels = paste0(seq(1990, 2020, by = 10), "-", seq(1999, 2029, by = 10))))

# Ensure `YearGroup` is a factor
repdata$YearGroup <- as.factor(repdata$YearGroup)

# Extract first country from `Con` (splitting at "/")
repdata <- repdata %>%
  mutate(Country = str_split_fixed(Con, "/", 2)[, 1] %>% str_trim())

# Count occurrences per country and filter those with 5+ observations
country_counts <- repdata %>%
  group_by(Country) %>%
  summarise(n = n())

repdata <- repdata %>%
  mutate(Country = ifelse(Country %in% country_counts$Country[country_counts$n >= 5], 
                          Country, "Other")) %>%
  mutate(Country = as.factor(Country))
```

### Model 1: GeWom \~ FemSig_P + Dat (Time-Based Analysis)

```{r}

logit_time <- glm(GeWom ~ FemSig_P + YearGroup, data = repdata, family = binomial)

stargazer(logit_time,
          title = "Logistic Regression: Impact of Time on Women's Provisions",
          dep.var.labels = "Provisions for Women (GeWom)",
          covariate.labels = c("Women Signatories", "Year Group"),
          omit.stat = c("aic", "bic"),
          star.cutoffs = c(0.1, 0.05, 0.01),
          intercept.bottom = TRUE,
          type = "text")

```

# Visualization of the Data

```{r}

# Aggregate by 10-year bins
bar_chart_data <- repdata %>%
  filter(Year >= 1990) %>%  # Exclude agreements before 1990
  group_by(YearGroup) %>%
  summarise(Prop_GeWom = mean(GeWom, na.rm = TRUE)) %>%
  filter(Prop_GeWom > 0)  # Remove bins with 0 proportion

# Plot
ggplot(bar_chart_data, aes(x = YearGroup, y = Prop_GeWom)) +
  geom_col(fill = "steelblue", alpha = 0.8) +
  geom_text(aes(label = round(Prop_GeWom, 2)), vjust = -0.5, size = 4) +
  labs(title = "Proportion of Peace Agreements with Women's Provisions (10-Year Intervals)",
       x = "10-Year Period",
       y = "Proportion of Agreements with Women's Provisions") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

### Model 2: GeWom \~ FemSig_P + Con (Country-Based Analysis)

```{r}

logit_country <- glm(GeWom ~ FemSig_P + Country, data = repdata, family = binomial)

stargazer(logit_country,
          title = "Logistic Regression: Impact of Country on Women's Provisions",
          dep.var.labels = "Provisions for Women (GeWom)",
          covariate.labels = c("Women Signatories", "Country"),
          omit.stat = c("aic", "bic"),
          star.cutoffs = c(0.1, 0.05, 0.01),
          intercept.bottom = TRUE,
          type = "text")

```

# Visualization of the Data

```{r}
# Standardize country names for mapping
country_mapping <- list(
  "Democratic Republic of Congo" = "Democratic Republic of the Congo",
  "South Sudan/Sudan" = "Sudan",
  "Bosnia and Herzegovina/Yugoslavia (former)" = "Bosnia and Herzegovina",
  "Kosovo/Serbia/Yugoslavia (former)" = "Serbia",
  "Macedonia/Yugoslavia (former)" = "North Macedonia",
  "Argentina/United Kingdom" = "Argentina"
)

repdata$Country <- recode(repdata$Country, !!!country_mapping)

# Aggregate data by country
country_data <- repdata %>%
  group_by(Country) %>%
  summarise(Prop_GeWom = mean(GeWom, na.rm = TRUE))

# Merge with world map
world_map <- map_data("world")
map_data <- left_join(world_map, country_data, by = c("region" = "Country"))

# Plot
ggplot(map_data, aes(x = long, y = lat, group = group, fill = Prop_GeWom)) +
  geom_polygon(color = "black") +
  scale_fill_gradient(low = "lightblue", high = "darkblue", na.value = "grey80") +
  labs(title = "Proportion of Peace Agreements with Women's Provisions by Country",
       fill = "Proportion") +
  theme_minimal()
```
